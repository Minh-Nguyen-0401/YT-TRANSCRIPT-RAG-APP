{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Extraction & Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transcription Extraction Approach & Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import whisper\n",
    "from unidecode import unidecode\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from src._check_retrieve_transcript import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_video_title(youtube_url):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"yt-dlp\", \"--get-title\", youtube_url],\n",
    "            capture_output=True, text=True, check=True, encoding=\"utf-8\"\n",
    "        )\n",
    "        title = result.stdout.strip()\n",
    "        return title\n",
    "    except subprocess.CalledProcessError:\n",
    "        return \"transcription\"\n",
    "\n",
    "def sanitize_title(title):\n",
    "    title = unidecode(title)\n",
    "    sanitized = re.sub(r'[^\\w\\s\\-]', '', title)\n",
    "    sanitized = sanitized.lower().strip().replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "def extract_yt_direct(youtube_url):\n",
    "    try:\n",
    "        url = youtube_url\n",
    "        video_id = re.search(r'.+?v=(.*)',url)[1]\n",
    "        trans = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        list_trans = []\n",
    "\n",
    "        for chunk in trans:\n",
    "            list_trans.append(chunk.get(\"text\"))\n",
    "\n",
    "        trans_fin = \" \".join(list_trans).replace(\"xa0\",\"\")\n",
    "        trans_fin_san = re.sub(r'[^\\w\\s\\-]', '', trans_fin)\n",
    "        trans_fin_san = re.sub(r'\\s+', ' ', trans_fin_san)\n",
    "        return trans_fin_san\n",
    "    except Exception as e:\n",
    "        return \"error\"\n",
    "\n",
    "def extract_transcription(url=None):\n",
    "    \"\"\"\n",
    "    function to extract transcription:\n",
    "        1. First get the title of the video\n",
    "        2. Check if transcript already in place (on github directory as a database)\n",
    "        3. If not, extract transcript directly online\n",
    "        4. If not, extract audio & transcribe\n",
    "        5. Export to github\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        transcription\n",
    "        title\n",
    "    \"\"\"\n",
    "    if url != None:\n",
    "        youtube_url = url\n",
    "    else:\n",
    "        youtube_url = str(input(\"Enter a youtube url: \"))\n",
    "    \n",
    "    # Get video title\n",
    "    title = sanitize_title(get_video_title(youtube_url))\n",
    "    title = title if len(title) < 38 else title[:38]\n",
    "\n",
    "    # Check if transcript already in place\n",
    "    check_trans = check_retrieve_transcript_db(title)\n",
    "    if check_trans == \"File not found\" or len(check_trans)==0:\n",
    "        # Case 1: Can extract transcript directly online\n",
    "        transcription = extract_yt_direct(youtube_url=youtube_url)\n",
    "        if \"error\" not in transcription and len(transcription) != 0:\n",
    "            export_to_github(title, transcription)\n",
    "            return transcription,title\n",
    "\n",
    "        # Case 2: Extract audio & transcribe\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                audio_file_path = os.path.join(temp_dir, \"audio.mp3\")\n",
    "                \n",
    "                # Download only audio using yt-dlp\n",
    "                subprocess.run([\n",
    "                    \"yt-dlp\",\n",
    "                    \"--extract-audio\",\n",
    "                    \"--audio-format\", \"mp3\",\n",
    "                    \"--output\", audio_file_path,\n",
    "                    \"--ffmpeg-location\", r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\",\n",
    "                    youtube_url\n",
    "                ], check=True)\n",
    "\n",
    "                print(\"Downloaded file path:\", audio_file_path)\n",
    "                print(\"Exists?\", os.path.isfile(audio_file_path))\n",
    "\n",
    "                os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\"\n",
    "                print(\"PATH:\", os.environ[\"PATH\"])\n",
    "                \n",
    "                # Load Whisper model\n",
    "                \"\"\"remember to install cuda version that matches your gpu: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\"\"\"\n",
    "                whisper_model = whisper.load_model(\"base\", device=\"cuda\")           \n",
    "                print(\"Model device:\", whisper_model.device)\n",
    "                \n",
    "                # Transcribe\n",
    "                cur_transcription = whisper_model.transcribe(audio_file_path, fp16=True)[\"text\"].strip()\n",
    "\n",
    "                export_to_github(title, cur_transcription)\n",
    "\n",
    "                return cur_transcription,title\n",
    "    else:\n",
    "        return check_trans.lower(),title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    \"\"\"Remove redundant characters that are not alphanumeric\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "    \"\"\"\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text).strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "\n",
    "    Returns:\n",
    "        text (str): cleaned text without stopwords\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Preprocessing & Storage Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_document(transcription):\n",
    "    text = transcription\n",
    "    text_documents = [Document(page_content=text)]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "    documents = text_splitter.split_documents(text_documents)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Embedding Model, Pine Cone DB & Store Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def store_vector_db(title,documents):\n",
    "    title = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title}-index\"\n",
    "    if index_name not in str(pc.list_indexes()):\n",
    "        pc.create_index(index_name,dimension = 1536, metric = \"cosine\", \n",
    "                        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "                        deletion_protection=\"disabled\")\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore.from_documents(documents=documents, embedding=embeddings, index_name=index_name\n",
    "    )\n",
    "        return pinecone\n",
    "    else:\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "        return pinecone\n",
    "\n",
    "def reset_index(title):\n",
    "    index_name = f\"{title}-index\"\n",
    "    index = pc.Index(host= pc.describe_index(index_name).host)\n",
    "    index.delete_index(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ExtractVideoTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        transcription, title = extract_transcription(X)\n",
    "        return {\"transcription\": transcription, \"title\": title}\n",
    "\n",
    "class CleanTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        trans = remove_stopwords(text_cleaner(X[\"transcription\"]))\n",
    "        return {\"transcription\": trans, \"title\": X[\"title\"]}\n",
    "\n",
    "class SplitDocuments(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        documents = split_document(X[\"transcription\"])\n",
    "        return {\"documents\": documents, \"title\": X[\"title\"]}\n",
    "\n",
    "class StoreVectorDB(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        title = X[\"title\"]\n",
    "        documents = X[\"documents\"]\n",
    "        store_vector_db(title,documents)\n",
    "        return {\"documents\": documents, \"title\": title}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Extraction & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for file data_trans/jensen_huang_--_nvidias_ceo_on_the_nex.txt...\n",
      "200\n",
      "Found file. Downloading...\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"extract\", ExtractVideoTranscription()),\n",
    "    (\"clean\", CleanTranscription()),\n",
    "    (\"split\", SplitDocuments()),\n",
    "    (\"store\", StoreVectorDB()),\n",
    "])\n",
    "\n",
    "preprocessed_dict = preprocessing_pipeline.fit_transform(str(input(\"Enter a youtube url: \")))\n",
    "documents, title = preprocessed_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1: Context-Based Querying Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def retrieve_context(input):\n",
    "    if detect(input) != \"en\":\n",
    "        query = translator.translate(input)\n",
    "        print(f\"Translated query: {query}\")\n",
    "    else:\n",
    "        query = input\n",
    "        print(f\"Original text already in English\")\n",
    "    \n",
    "    context = store_vector_db(title,documents) \\\n",
    "                .as_retriever(search_type = \"similarity_score_threshold\",search_kwargs={'score_threshold': 0.4}) \\\n",
    "                .get_relevant_documents(query)\n",
    "    compiled_docu = \" \".join([doc.page_content for doc in context])\n",
    "    print(\"Retrieved Context:\", compiled_docu, \"\\n-----\\n\")\n",
    "    return compiled_docu\n",
    "\n",
    "def query_from_context_main():\n",
    "    template = \"\"\"\n",
    "    Think step by step before answering the question based on the context below. If you can't find the answer in the context below, say that you don't know.\n",
    "\n",
    "    **Context:** {context}\n",
    "\n",
    "    **Question:** {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    retriever_step = RunnableLambda(retrieve_context)\n",
    "    retriever = RunnableParallel(context = retriever_step,\n",
    "                        question=RunnablePassthrough(), \n",
    "                        #  language = RunnablePassthrough()\n",
    "                        )\n",
    "    retriever | prompt | model | parser\n",
    "    return retriever | prompt | model | parser \n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def web_search_tool(query):\n",
    "    web_search_tool = TavilySearchResults(k=3)\n",
    "    results = web_search_tool.invoke(query)\n",
    "    extracted_results = \"\\n\".join([remove_stopwords(re.sub(r\"[^a-zA-Z0-9\\s.,!?]\",\"\",res[\"content\"].replace(\"\\n\",\" \").strip())) for res in results])\n",
    "    return extracted_results\n",
    "\n",
    "def alternative_web_search_context(prev_result):\n",
    "     if \"i don't know\" in prev_result.lower():\n",
    "          return True\n",
    "\n",
    "def build_chain_web():\n",
    "    search_step = RunnableLambda(lambda q: web_search_tool(q))  # Define search tool logic\n",
    "    retriever_web = RunnableParallel(context=search_step, question=RunnablePassthrough())\n",
    "    web_prompt = ChatPromptTemplate.from_template(\"Web search-based context:\\n{context}\\n\\n**Question:** {question}\")\n",
    "    return retriever_web | web_prompt | model | parser\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def start_conversation():\n",
    "\n",
    "    chain_main = query_from_context_main()\n",
    "    chain_web = build_chain_web()\n",
    "    \n",
    "    question_no = 0\n",
    "    while True:\n",
    "        query = str(input(\"Ask me a question (type 'exit' to quit): \")).lower()\n",
    "\n",
    "\n",
    "        if query == 'exit':\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "        \n",
    "        question_no += 1\n",
    "        print(f\"\\nQuestion {question_no}:\")\n",
    "        \n",
    "        main_result = []\n",
    "        for s in chain_main.stream(query):\n",
    "            main_result.append(s)\n",
    "            print(s, end =\"\",flush=True)\n",
    "        \n",
    "        if alternative_web_search_context(\"\".join(main_result)):\n",
    "            print(f\"\\nSwitching to web search tool...\")\n",
    "            for s in chain_web.stream(query):\n",
    "                main_result.append(s)\n",
    "                print(s, end =\"\",flush=True)\n",
    "        print(\"\\n\",\"---\"*20,\"\\n\")\n",
    "\n",
    "        subquery = str(input(\"Continue? (click Enter): \"))\n",
    "        if subquery.lower() == '':\n",
    "             continue\n",
    "        else:\n",
    "             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"491pt\" height=\"383pt\"\n",
       " viewBox=\"0.00 0.00 491.14 382.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 378.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-378.5 487.14,-378.5 487.14,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"230.68\" cy=\"-356.5\" rx=\"80.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"230.68\" y=\"-351.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Start Conversation</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-283.5\" rx=\"109.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query from Context Main</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M207.24,-338.85C194.26,-329.64 177.92,-318.04 163.68,-307.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.09,-305.35 155.91,-302.41 162.04,-311.05 166.09,-305.35\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"332.68\" cy=\"-283.5\" rx=\"74.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.68\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Build Chain Web</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;C -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>A&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M254.6,-338.85C268.02,-329.51 284.98,-317.7 299.66,-307.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"301.47,-310.49 307.67,-301.91 297.47,-304.75 301.47,-310.49\"/>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-195\" rx=\"73.87\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Retrieve Context</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-265.41C130.68,-253.76 130.68,-238.05 130.68,-224.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-224.86 130.68,-214.86 127.18,-224.86 134.18,-224.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.81\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Retrieve Context</text>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"332.68\" cy=\"-195\" rx=\"74.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.68\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Web Search Tool</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;E -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>C&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M332.68,-265.41C332.68,-253.76 332.68,-238.05 332.68,-224.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"336.18,-224.86 332.68,-214.86 329.18,-224.86 336.18,-224.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"379.18\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Web Search Tool</text>\n",
       "</g>\n",
       "<!-- G -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>G</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-106.5\" rx=\"77.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Main Result</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;G -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>D&#45;&gt;G</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-176.91C130.68,-165.26 130.68,-149.55 130.68,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-136.36 130.68,-126.36 127.18,-136.36 134.18,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.43\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Main Result</text>\n",
       "</g>\n",
       "<!-- H -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>H</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"332.68\" cy=\"-106.5\" rx=\"73.87\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.68\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Web Result</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;H -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>E&#45;&gt;H</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M332.68,-176.91C332.68,-165.26 332.68,-149.55 332.68,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"336.18,-136.36 332.68,-126.36 329.18,-136.36 336.18,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"378.81\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Web Result</text>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-18\" rx=\"130.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Alternative Web Search Context</text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;H -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>F&#45;&gt;H</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.55,-27.84C262.84,-33.24 283.99,-41.49 301.68,-54 310.26,-60.06 316.88,-69.32 321.76,-78.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.55,-79.71 326.05,-87.19 324.85,-76.67 318.55,-79.71\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.2\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Switch to Web Search</text>\n",
       "</g>\n",
       "<!-- G&#45;&gt;F -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>G&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-88.41C130.68,-76.76 130.68,-61.05 130.68,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-47.86 130.68,-37.86 127.18,-47.86 134.18,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.93\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Check Alternative Web Search</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"405.68\" cy=\"-356.5\" rx=\"77.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.68\" y=\"-351.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">End Conversation</text>\n",
       "</g>\n",
       "<!-- G&#45;&gt;I -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>G&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.54,-117.1C212.37,-119.65 231.76,-122.3 249.68,-124.5 269.19,-126.89 412.43,-127.98 425.68,-142.5 472.31,-193.55 440.55,-282.98 419.75,-327.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"416.69,-326.27 415.53,-336.8 423,-329.29 416.69,-326.27\"/>\n",
       "</g>\n",
       "<!-- H&#45;&gt;I -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>H&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M402.86,-112.61C422.27,-117.6 441.36,-126.6 453.68,-142.5 496.96,-198.37 478.67,-235.78 452.68,-301.5 448.48,-312.14 441.22,-322.1 433.65,-330.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"431.25,-327.96 426.81,-337.58 436.28,-332.82 431.25,-327.96\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2b16247c200>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_flow():\n",
    "    dot = Digraph(comment='Code Flow')\n",
    "\n",
    "    # Define nodes\n",
    "    dot.node('A', 'Start Conversation')\n",
    "    dot.node('B', 'Query from Context Main')\n",
    "    dot.node('C', 'Build Chain Web')\n",
    "    dot.node('D', 'Retrieve Context')\n",
    "    dot.node('E', 'Web Search Tool')\n",
    "    dot.node('F', 'Alternative Web Search Context')\n",
    "    dot.node('G', 'Print Main Result')\n",
    "    dot.node('H', 'Print Web Result')\n",
    "    dot.node('I', 'End Conversation')\n",
    "\n",
    "    # Define edges\n",
    "    dot.edges(['AB', 'AC'])\n",
    "    dot.edge('B', 'D', label='Retrieve Context')\n",
    "    dot.edge('C', 'E', label='Web Search Tool')\n",
    "    dot.edge('D', 'G', label='Print Main Result')\n",
    "    dot.edge('E', 'H', label='Print Web Result')\n",
    "    dot.edge('G', 'F', label='Check Alternative Web Search')\n",
    "    dot.edge('F', 'H', label='Switch to Web Search', constraint='false')\n",
    "    dot.edge('G', 'I', constraint='false')\n",
    "    dot.edge('H', 'I', constraint='false')\n",
    "\n",
    "    return dot\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "dot = visualize_flow()\n",
    "display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1:\n",
      "Original text already in English\n",
      "Retrieved Context: jensen first time human history producing manufacturing intelligence like production raw material comes lot genius goes box comes intelligence thats refined lukas youre listening gradient dissent show machine learning real world im host lukas biewald today gradient dissent interviewed guest ive looking forward interviewing quite long time jensen huang ceo founder nvidia youve trained machine learning model youve probably trained nvidia hardware get machine learning talk views future holds super fun interview really hope enjoy lukas right well thanks much collected questions community ton theres questions im sure get im going get questions first jensen okay lukas wanted start number one question wanted ask ive always wondered think almost everyone training machine learning models days uses manufacturing lukas well thanks much thats really kind im touched appreciate jensen keep great work lukas youre enjoying interviews want learn please click link show notes description find links papers mentioned supplemental material transcription work really hard produce check write little code put something together jensen long time get tinker people wonderful thing nvidia 24000 people could tinker little something everybody amount tinkering thats going around company incredible theres phrase say reach friends really see way reach friends company brainstorm little something go try something somebody else theyre brainstorming try something thats guess tinkering scale lukas thats super cool love another question lot people askim curious people originally think nvidia games gamer play video games jensen havent played much games see almost every game goes get benefit collaboration every game company world theyre labs people tell ill run go check play bit last time probablyone favorite games battlefield first came kids teenagers home coming gaming age three us really need tapeout bonus achievement bonus everybodys trying best thats one example lukas thats great one else youve got others id love hear jensen okay heres another one well want diplomatic well theres many ceos could using techniques hate critical criticism style tend one ones theres anything need say tend like say team group working hearing things im hearing things everybody else hearing things instead translated lukas interesting thats really unusual perspective think lot people think absolutely must one ones across company think like reports jensen dont dont many leaders dont criticize dont reason probably important ceos becauseyou cant eliminate completely want reduce amount jensen told jensen told way somehow steer conversation otherwise done merits instead somehow translated \n",
      "-----\n",
      "\n",
      "Jensen is Jensen Huang, the CEO and founder of NVIDIA.\n",
      " ------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: (Advanced) Summarization Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/18/2024 11:40:31 INFO Loaded model pszemraj/led-large-book-summary to cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from textsum.summarize import Summarizer\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "model_name = \"pszemraj/led-large-book-summary\"\n",
    "summarizer = Summarizer(\n",
    "    model_name_or_path=model_name\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "def fetch_list_pinecone(title) -> pd.DataFrame:\n",
    "    # Define index\n",
    "    title_refined = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title_refined}-index\"\n",
    "\n",
    "    index = pc.Index(name = index_name, host = pc.describe_index(index_name).host)\n",
    "\n",
    "    # Define vector_id\n",
    "    id_list = []\n",
    "    for id in index.list():\n",
    "        for i in id:\n",
    "            id_list.append(i)\n",
    "\n",
    "    # Fetch vector list including metadata\n",
    "    fetch_list = index.fetch(ids=id_list)\n",
    "\n",
    "    # Return df of id, text, vector values\n",
    "    list_vec = []\n",
    "    for key, content in fetch_list[\"vectors\"].items():\n",
    "        id = key\n",
    "        text = content[\"metadata\"][\"text\"]\n",
    "        values = content[\"values\"]\n",
    "        list_vec.append([id,text,values])\n",
    "    \n",
    "    df_vec_extracted = pd.DataFrame(list_vec, columns=[\"id\", \"text\", \"values\"])\n",
    "\n",
    "    return df_vec_extracted\n",
    "\n",
    "def preprocess_run_kmeans(df_vec_extracted, n = 8) -> pd.DataFrame:\n",
    "    # Split vector values to a separate df to run kmeans\n",
    "    df_vec_text = df_vec_extracted.iloc[:,:2]\n",
    "\n",
    "    df_vec_val = df_vec_extracted.loc[:,[\"id\",\"values\"]]\n",
    "    df_vec_val = pd.concat([df_vec_val[[\"id\"]], pd.DataFrame(df_vec_val[\"values\"].tolist())],axis=1)    \n",
    "\n",
    "    n_clusters = n\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df_vec_val[\"cluster\"] = kmeans.fit_predict(df_vec_val.iloc[:, 1:])\n",
    "    df_vec_text_clustered = pd.merge(df_vec_text,df_vec_val[\"cluster\"],right_index=True,left_index=True)\n",
    "    \n",
    "    # Return final clustered results in df form\n",
    "    clustered_texts = df_vec_text_clustered.groupby(\"cluster\")[\"text\"].apply(\" \".join).reset_index()\n",
    "    return clustered_texts\n",
    "\n",
    "def summarize_text(input):\n",
    "    out_str = summarizer.summarize_string(input)\n",
    "    return out_str\n",
    "\n",
    "def pre_summarize_chunk(title):\n",
    "    df_vec_extracted = fetch_list_pinecone(title)\n",
    "    clustered_texts = preprocess_run_kmeans(df_vec_extracted, n = 8)\n",
    "    clustered_texts[\"summarized_text\"] = clustered_texts[\"text\"].apply(lambda x: summarize_text(x))\n",
    "    input_sum=\"; \".join(clustered_texts[\"summarized_text\"].values)\n",
    "    return input_sum\n",
    "\n",
    "def summarize_main(title=title):\n",
    "    summarize_temp = \"\"\"\n",
    "    **Summarize the main points** and organize the information into a coherent summary based on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Ensure the summary is concise, clear, and covers all key details.\n",
    "    \"\"\"\n",
    "\n",
    "    summarize_prompt = ChatPromptTemplate.from_template(summarize_temp)\n",
    "\n",
    "    input_sum = pre_summarize_chunk(title)\n",
    "\n",
    "    # summarization chain of actions\n",
    "    sum_chain = summarize_prompt | model | parser\n",
    "\n",
    "    sum_chunk = []\n",
    "\n",
    "    for s in sum_chain.stream(input_sum):\n",
    "        sum_chunk.append(s)\n",
    "        print(s, end=\"\", flush=True)\n",
    "    return \"\".join(sum_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f458b0855d4450b69cf06d6bd8912c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a77069a333849de996796d7f4272c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f930bf1247d64e4e82f526c7206e9d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9c51c4f3534a89bb2661d62a5b91a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b9d483113f403bad4fe16816abcac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a15f30d5810427b8142674514eb3b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041178b609e1471695a86ce2451f7ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7a4a77d8e4404199c32d68f0a981dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/18/2024 11:41:53 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chapter emphasizes the concept of \"networks\" as fundamental to understanding daily life and its various elements, particularly in the fields of artificial intelligence and machine learning. It begins by listing the top 10 significant developments in technology, focusing on their interrelationships and collective impact on our lives. Key advancements discussed include:\n",
      "\n",
      "1. The advent of affordable semiconductor chips, facilitating computational advances.\n",
      "2. Enhanced speed and power in data processing.\n",
      "3. A shift from brute force methods to logic, statistics, and synthetic biology.\n",
      "4. The innovation of the floppy drive, enabling individuals to build homemade supercomputers.\n",
      "\n",
      "The narrative shifts to the industrial revolution’s next phase, highlighting the role of machine learning and artificial intelligence in transforming work and thought processes. It references the pioneering work of Jensen and his company in creating new semiconductor technologies and algorithms that enhance computing capabilities.\n",
      "\n",
      "Lucas expresses particular interest in future applications, such as virtual reality, and mentions his creation—a robot with an avatar capable of language comprehension. The author reflects on the transformative power of machine learning, which turns raw data into neural networks, revolutionizing software development and enabling engineers to innovate across diverse fields like agriculture, medicine, and architecture.\n",
      "\n",
      "Despite the excitement around these advancements, the author critiques the inefficacy of concepts like \"tapeout bonuses,\" which aim to reward employee efforts but often fail due to resource limitations in companies. He argues that successful innovation should focus on creating substantial value rather than merely achieving minimum viable products. Ultimately, the chapter explores how interconnected technological developments are reshaping our understanding of productivity and progress in various domains."
     ]
    }
   ],
   "source": [
    "output = summarize_main(title);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
