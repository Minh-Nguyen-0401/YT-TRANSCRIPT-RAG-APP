{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Extraction & Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transcription Extraction Approach & Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import whisper\n",
    "from unidecode import unidecode\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from src._check_retrieve_transcript import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_video_title(youtube_url):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"yt-dlp\", \"--get-title\", youtube_url],\n",
    "            capture_output=True, text=True, check=True, encoding=\"utf-8\"\n",
    "        )\n",
    "        title = result.stdout.strip()\n",
    "        return title\n",
    "    except subprocess.CalledProcessError:\n",
    "        return \"transcription\"\n",
    "\n",
    "def sanitize_title(title):\n",
    "    title = unidecode(title)\n",
    "    sanitized = re.sub(r'[^\\w\\s\\-]', '', title)\n",
    "    sanitized = sanitized.lower().strip().replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "def extract_yt_direct(youtube_url):\n",
    "    try:\n",
    "        url = youtube_url\n",
    "        video_id = re.search(r'.+?v=(.*)',url)[1]\n",
    "        trans = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        list_trans = []\n",
    "\n",
    "        for chunk in trans:\n",
    "            list_trans.append(chunk.get(\"text\"))\n",
    "\n",
    "        trans_fin = \" \".join(list_trans).replace(\"xa0\",\"\")\n",
    "        trans_fin_san = re.sub(r'[^\\w\\s\\-]', '', trans_fin)\n",
    "        trans_fin_san = re.sub(r'\\s+', ' ', trans_fin_san)\n",
    "        return trans_fin_san\n",
    "    except Exception as e:\n",
    "        return \"error\"\n",
    "\n",
    "def extract_transcription(url=None):\n",
    "    \"\"\"\n",
    "    function to extract transcription:\n",
    "        1. First get the title of the video\n",
    "        2. Check if transcript already in place (on github directory as a database)\n",
    "        3. If not, extract transcript directly online\n",
    "        4. If not, extract audio & transcribe\n",
    "        5. Export to github\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        transcription\n",
    "        title\n",
    "    \"\"\"\n",
    "    if url != None:\n",
    "        youtube_url = url\n",
    "    else:\n",
    "        youtube_url = str(input(\"Enter a youtube url: \"))\n",
    "    \n",
    "    # Get video title\n",
    "    title = sanitize_title(get_video_title(youtube_url))\n",
    "    title = title if len(title) < 38 else title[:38]\n",
    "\n",
    "    # Check if transcript already in place\n",
    "    check_trans = check_retrieve_transcript_db(title)\n",
    "    if check_trans == \"File not found\" or len(check_trans)==0:\n",
    "        # Case 1: Can extract transcript directly online\n",
    "        transcription = extract_yt_direct(youtube_url=youtube_url)\n",
    "        if \"error\" not in transcription and len(transcription) != 0:\n",
    "            export_to_github(title, transcription)\n",
    "            return transcription,title\n",
    "\n",
    "        # Case 2: Extract audio & transcribe\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                audio_file_path = os.path.join(temp_dir, \"audio.mp3\")\n",
    "                \n",
    "                # Download only audio using yt-dlp\n",
    "                subprocess.run([\n",
    "                    \"yt-dlp\",\n",
    "                    \"--extract-audio\",\n",
    "                    \"--audio-format\", \"mp3\",\n",
    "                    \"--output\", audio_file_path,\n",
    "                    \"--ffmpeg-location\", r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\",\n",
    "                    youtube_url\n",
    "                ], check=True)\n",
    "\n",
    "                print(\"Downloaded file path:\", audio_file_path)\n",
    "                print(\"Exists?\", os.path.isfile(audio_file_path))\n",
    "\n",
    "                os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\"\n",
    "                print(\"PATH:\", os.environ[\"PATH\"])\n",
    "                \n",
    "                # Load Whisper model\n",
    "                \"\"\"remember to install cuda version that matches your gpu: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\"\"\"\n",
    "                whisper_model = whisper.load_model(\"base\", device=\"cuda\")           \n",
    "                print(\"Model device:\", whisper_model.device)\n",
    "                \n",
    "                # Transcribe\n",
    "                cur_transcription = whisper_model.transcribe(audio_file_path, fp16=True)[\"text\"].strip()\n",
    "\n",
    "                export_to_github(title, cur_transcription)\n",
    "\n",
    "                return cur_transcription,title\n",
    "    else:\n",
    "        return check_trans,title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    \"\"\"Remove redundant characters that are not alphanumeric\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "    \"\"\"\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text).strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "\n",
    "    Returns:\n",
    "        text (str): cleaned text without stopwords\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Preprocessing & Storage Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_document(title):\n",
    "    path_to_doc = f\"./data_trans/{title}_transcript.txt\"\n",
    "    loader = TextLoader(path_to_doc)\n",
    "    text_documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "    documents = text_splitter.split_documents(text_documents)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Embedding Model, Pine Cone DB & Store Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def store_vector_db(title,documents):\n",
    "    title = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title}-index\"\n",
    "    if index_name not in str(pc.list_indexes()):\n",
    "        pc.create_index(index_name,dimension = 1536, metric = \"cosine\", \n",
    "                        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "                        deletion_protection=\"disabled\")\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore.from_documents(documents=documents, embedding=embeddings, index_name=index_name\n",
    "    )\n",
    "        return pinecone\n",
    "    else:\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "        return pinecone\n",
    "\n",
    "def reset_index(title):\n",
    "    index_name = f\"{title}-index\"\n",
    "    index = pc.Index(host= pc.describe_index(index_name).host)\n",
    "    index.delete_index(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ExtractVideoTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        transcription, title = extract_transcription(X)\n",
    "        return {\"transcription\": transcription, \"title\": title}\n",
    "\n",
    "class CleanTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        trans = remove_stopwords(text_cleaner(X[\"transcription\"]))\n",
    "        return {\"transcription\": trans, \"title\": X[\"title\"]}\n",
    "\n",
    "class SplitDocuments(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        documents = split_document(X[\"title\"])\n",
    "        return {\"documents\": documents, \"title\": X[\"title\"]}\n",
    "\n",
    "class StoreVectorDB(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        title = X[\"title\"]\n",
    "        documents = X[\"documents\"]\n",
    "        store_vector_db(title,documents)\n",
    "        return {\"documents\": documents, \"title\": title}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Extraction & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for file data_trans/jensen_huang_--_nvidias_ceo_on_the_nex.txt...\n",
      "200\n",
      "Found file. Downloading...\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"extract\", ExtractVideoTranscription()),\n",
    "    (\"clean\", CleanTranscription()),\n",
    "    (\"split\", SplitDocuments()),\n",
    "    (\"store\", StoreVectorDB()),\n",
    "])\n",
    "\n",
    "preprocessed_dict = preprocessing_pipeline.fit_transform(str(input(\"Enter a youtube url: \")))\n",
    "documents, title = preprocessed_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1: Context-Based Querying Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def retrieve_context(input):\n",
    "    if detect(input) != \"en\":\n",
    "        query = translator.translate(input)\n",
    "        print(f\"Translated query: {query}\")\n",
    "    else:\n",
    "        query = input\n",
    "        print(f\"Original text already in English\")\n",
    "    \n",
    "    context = store_vector_db(title,documents) \\\n",
    "                .as_retriever(search_type = \"similarity_score_threshold\",search_kwargs={'score_threshold': 0.2}) \\\n",
    "                .get_relevant_documents(query)\n",
    "    compiled_docu = \" \".join([doc.page_content for doc in context])\n",
    "    print(\"Retrieved Context:\", compiled_docu, \"\\n-----\\n\")\n",
    "    return compiled_docu\n",
    "\n",
    "def query_from_context_main():\n",
    "    template = \"\"\"\n",
    "    Think step by step before answering the question based on the context below. If you can't find the answer in the context below, say that you don't know.\n",
    "\n",
    "    **Context:** {context}\n",
    "\n",
    "    **Question:** {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    retriever_step = RunnableLambda(retrieve_context)\n",
    "\n",
    "    retriever = RunnableParallel(context = retriever_step, \n",
    "                                question=RunnablePassthrough(), \n",
    "                                #  language = RunnablePassthrough()\n",
    "                                )\n",
    "    chain = retriever | prompt | model | parser\n",
    "\n",
    "    while True:\n",
    "        query = str(input(\"Ask me a question (type 'exit' to quit): \"))\n",
    "        if query.lower() == 'exit':\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "        for s in chain.stream(query):\n",
    "            print(s, end =\"\",flush=True)\n",
    "        print(\"\\n\",\"---\"*20)\n",
    "\n",
    "        subquery = str(input(\"Continue? (click Enter): \"))\n",
    "        if subquery.lower() == '':\n",
    "             continue\n",
    "        else:\n",
    "             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text already in English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2024 12:44:55 INFO HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context: of artificial intelligence Second is the next era of AI Weve done a really good job with soft AI thats in the cloud Recommending music recommending movies and the next item in the cart and so on and so forth Its really incredible The thing that we would really like to do is toif we want to take AI into the point of where people are and into this next phase of its journey AI has to learn the laws of physics Many of the worlds challenges whether its climate science or autonomous vehicles or manufacturing or whatever it is the AI cant just make a prediction It has to make a prediction that obeys the laws of physics conservation of matter conservation of energy and such It has to understand the concept of synchronous time It has to be working within our time There are a lot of these types of is going to be incredible So I think that in the coming years were gonna see superhuman AIs They wont be like us but in many domains of activities theyd be quite incredible Lukas But I imagine where you sit youre watching AI help with chip manufacturing and design better chips And youre probably seeing that have compounding returns which I think is sort of the thesis behind the singularity right Its sort of AI starts to create AI You just see this exponential Jensen Thats exactly right Look were not going to be able to build next-generation chips without AI And thats kind of a remarkable statement That all of the chip design process the architectural processtoday we have 5 of the worlds top 500 supercomputers in our company and we are producing software that gets shipped with all of our software that gets shipped with all of our AI chips Without AI we cant produce software that runs the AI And in the future without AI we wouldnt be able to design the chips that we use to run AI So thats right the circular positive feedback system is about to go into turbocharge I have every confidence that the next 10 years were going to see even greater advances Not necessarily at the transistor level but absolutely at the computation level Lukas Do you have any concerns aboutas compute gets more and more important to advances in science that theres impact on the climate or even impacts on access of whos able to make scientific discoveries or whos able to kind of make the next really exciting company if they need a supercomputer to do that Jensen First of all one of our greatest almost anybody can download a pre-trained model and perform superhuman capabilities for their application domain by retraining it by adapting it by applying a transfer of learning capability to it I think artificial intelligence is the most powerful force that has come along And one of its benefits is going to be to democratize computer science Now one of the things that you mentioned earlier about energyI think that one of the greatest projects were working on is this thing called Earth-2 which is a digital tool whichwere going to try to build a digital twin to mimic the climate of the earth Its a multi-physics problem thermal dynamics and fluid dynamics and chemistry problem and a biology problem and the human driver problem and economic problem All of it contributes in this \n",
      "-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2024 12:44:58 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or artificial intelligence, refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding. In the context provided, AI is described as a powerful tool that has evolved from basic functions like recommending music and movies to more complex applications that require understanding the laws of physics and making predictions that adhere to these laws. AI is expected to play a crucial role in various fields, including climate science, autonomous vehicles, and chip manufacturing, with the potential for significant advancements in the coming years.\n",
      " ------------------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "query_from_context_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: (Advanced) Summarization Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2024 12:37:35 INFO Loaded model pszemraj/led-large-book-summary to cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from textsum.summarize import Summarizer\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "model_name = \"pszemraj/led-large-book-summary\"\n",
    "summarizer = Summarizer(\n",
    "    model_name_or_path=model_name\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "def fetch_list_pinecone(title) -> pd.DataFrame:\n",
    "    # Define index\n",
    "    title_refined = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title_refined}-index\"\n",
    "\n",
    "    index = pc.Index(name = index_name, host = pc.describe_index(index_name).host)\n",
    "\n",
    "    # Define vector_id\n",
    "    id_list = []\n",
    "    for id in index.list():\n",
    "        for i in id:\n",
    "            id_list.append(i)\n",
    "\n",
    "    # Fetch vector list including metadata\n",
    "    fetch_list = index.fetch(ids=id_list)\n",
    "\n",
    "    # Return df of id, text, vector values\n",
    "    list_vec = []\n",
    "    for key, content in fetch_list[\"vectors\"].items():\n",
    "        id = key\n",
    "        text = content[\"metadata\"][\"text\"]\n",
    "        values = content[\"values\"]\n",
    "        list_vec.append([id,text,values])\n",
    "    \n",
    "    df_vec_extracted = pd.DataFrame(list_vec, columns=[\"id\", \"text\", \"values\"])\n",
    "\n",
    "    return df_vec_extracted\n",
    "\n",
    "def preprocess_run_kmeans(df_vec_extracted, n = 8) -> pd.DataFrame:\n",
    "    # Split vector values to a separate df to run kmeans\n",
    "    df_vec_text = df_vec_extracted.iloc[:,:2]\n",
    "\n",
    "    df_vec_val = df_vec_extracted.loc[:,[\"id\",\"values\"]]\n",
    "    df_vec_val = pd.concat([df_vec_val[[\"id\"]], pd.DataFrame(df_vec_val[\"values\"].tolist())],axis=1)    \n",
    "\n",
    "    n_clusters = n\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df_vec_val[\"cluster\"] = kmeans.fit_predict(df_vec_val.iloc[:, 1:])\n",
    "    df_vec_text_clustered = pd.merge(df_vec_text,df_vec_val[\"cluster\"],right_index=True,left_index=True)\n",
    "    \n",
    "    # Return final clustered results in df form\n",
    "    clustered_texts = df_vec_text_clustered.groupby(\"cluster\")[\"text\"].apply(\" \".join).reset_index()\n",
    "    return clustered_texts\n",
    "\n",
    "def summarize_text(input):\n",
    "    out_str = summarizer.summarize_string(input)\n",
    "    return out_str\n",
    "\n",
    "def pre_summarize_chunk(title):\n",
    "    df_vec_extracted = fetch_list_pinecone(title)\n",
    "    clustered_texts = preprocess_run_kmeans(df_vec_extracted, n = 8)\n",
    "    clustered_texts[\"summarized_text\"] = clustered_texts[\"text\"].apply(lambda x: summarize_text(x))\n",
    "    input_sum=\"; \".join(clustered_texts[\"summarized_text\"].values)\n",
    "    return input_sum\n",
    "\n",
    "def summarize_main(title=title):\n",
    "    summarize_temp = \"\"\"\n",
    "    **Summarize the main points** and organize the information into a coherent summary based on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Ensure the summary is concise, clear, and covers all key details.\n",
    "    \"\"\"\n",
    "\n",
    "    summarize_prompt = ChatPromptTemplate.from_template(summarize_temp)\n",
    "\n",
    "    input_sum = pre_summarize_chunk(title)\n",
    "\n",
    "    # summarization chain of actions\n",
    "    sum_chain = summarize_prompt | model | parser\n",
    "\n",
    "    sum_chunk = []\n",
    "\n",
    "    for s in sum_chain.stream(input_sum):\n",
    "        sum_chunk.append(s)\n",
    "        print(s, end=\"\", flush=True)\n",
    "    return \"\".join(sum_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e18835183047189586725f905798f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd31dfba689f4e0cbac02099330589ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6588fd7904452b9e35f5a41e7ea146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1243530eab664e5cbe5570bccec1675a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503f71d77dd54a4d86e59e30ed1093cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d67f135d48e4ce189b52f84e1c56357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab8dcf2acd64b6985525c2dc076bfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08bf100369c49ab942bbf5d378a5713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/16/2024 12:39:45 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speech emphasizes the increasing importance of the public in holding executives accountable and fostering transparency in decision-making. The speaker, Jensen, reflects on his journey to embrace vulnerability and authenticity in communication, moving away from a secretive approach to one that values openness.\n",
      "\n",
      "Jensen shares a personal anecdote about a friend suggesting his son learn to build a supercomputer using NVIDIA's CUDA SDK, highlighting the growing significance of GPUs in various fields, including deep learning. He predicts that the next decade will witness not only superhuman AIs but also advancements in areas such as medicine and climate science, driven by machine learning and deep learning technologies.\n",
      "\n",
      "He contrasts early machine learning with deep learning, emphasizing the refinement process involved in developing software and the role of MLOPS in scaling intelligence. Jensen discusses his company's mission to advance the art of intelligence by teaching machines the laws of physics and tackling complex, long-term problems that require meaningful effort.\n",
      "\n",
      "During a Q&A session, he addresses the challenges of applying machine learning to real-world problems, noting technical bottlenecks like data accessibility. Jensen also discusses the importance of creating an environment that allows talented individuals to thrive, asserting that a CEO's role is to foster curiosity and innovation.\n",
      "\n",
      "Furthermore, he explains NVIDIA's approach to product design, which accommodates various user needs—from gamers to scientists—by creating adaptable chips. Jensen believes that the company's success stems from its combination of diverse product offerings and expertise, positioning them well to address the challenges of artificial intelligence across industries.\n",
      "\n",
      "In conclusion, Jensen emphasizes the importance of understanding the implications of technology on future software development and the need for a comprehensive approach to creating solutions that benefit various sectors. He envisions using AI to build digital models that can address significant global challenges, such as climate change."
     ]
    }
   ],
   "source": [
    "output = summarize_main(title);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
