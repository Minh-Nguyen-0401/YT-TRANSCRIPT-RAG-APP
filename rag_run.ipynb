{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Extraction & Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transcription Extraction Approach & Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import whisper\n",
    "from unidecode import unidecode\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from src._check_retrieve_transcript import *\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_video_title(youtube_url):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"yt-dlp\", \"--get-title\", youtube_url],\n",
    "            capture_output=True, text=True, check=True, encoding=\"utf-8\"\n",
    "        )\n",
    "        title = result.stdout.strip()\n",
    "        return title\n",
    "    except subprocess.CalledProcessError:\n",
    "        return \"transcription\"\n",
    "\n",
    "def sanitize_title(title):\n",
    "    title = unidecode(title)\n",
    "    sanitized = re.sub(r'[^\\w\\s\\-]', '', title)\n",
    "    sanitized = sanitized.lower().strip().replace(' ', '_')\n",
    "    return sanitized\n",
    "\n",
    "def extract_yt_direct(youtube_url):\n",
    "    try:\n",
    "        url = youtube_url\n",
    "        video_id = re.search(r'.+?v=(.*)',url)[1]\n",
    "        trans = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        list_trans = []\n",
    "\n",
    "        for chunk in trans:\n",
    "            list_trans.append(chunk.get(\"text\"))\n",
    "\n",
    "        trans_fin = \" \".join(list_trans).replace(\"xa0\",\"\")\n",
    "        trans_fin_san = re.sub(r'[^\\w\\s\\-]', '', trans_fin)\n",
    "        trans_fin_san = re.sub(r'\\s+', ' ', trans_fin_san)\n",
    "        return trans_fin_san\n",
    "    except Exception as e:\n",
    "        return \"error\"\n",
    "\n",
    "def extract_transcription(url=None):\n",
    "    \"\"\"\n",
    "    function to extract transcription:\n",
    "        1. First get the title of the video\n",
    "        2. Check if transcript already in place (on github directory as a database)\n",
    "        3. If not, extract transcript directly online\n",
    "        4. If not, extract audio & transcribe\n",
    "        5. Export to github\n",
    "\n",
    "    Args:\n",
    "        url (str, optional): _description_. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        transcription\n",
    "        title\n",
    "    \"\"\"\n",
    "    if url != None:\n",
    "        youtube_url = url\n",
    "    else:\n",
    "        youtube_url = str(input(\"Enter a youtube url: \"))\n",
    "    \n",
    "    # Get video title\n",
    "    title = sanitize_title(get_video_title(youtube_url))\n",
    "    title = title if len(title) < 38 else title[:38]\n",
    "\n",
    "    # Check if transcript already in place\n",
    "    check_trans = check_retrieve_transcript_db(title)\n",
    "    if check_trans == \"File not found\" or len(check_trans)==0:\n",
    "        # Case 1: Can extract transcript directly online\n",
    "        transcription = extract_yt_direct(youtube_url=youtube_url)\n",
    "        if \"error\" not in transcription and len(transcription) != 0:\n",
    "            export_to_github(title, transcription)\n",
    "            return transcription,title\n",
    "\n",
    "        # Case 2: Extract audio & transcribe\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                audio_file_path = os.path.join(temp_dir, \"audio.mp3\")\n",
    "                \n",
    "                # Download only audio using yt-dlp\n",
    "                subprocess.run([\n",
    "                    \"yt-dlp\",\n",
    "                    \"--extract-audio\",\n",
    "                    \"--audio-format\", \"mp3\",\n",
    "                    \"--output\", audio_file_path,\n",
    "                    \"--ffmpeg-location\", r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\",\n",
    "                    youtube_url\n",
    "                ], check=True)\n",
    "\n",
    "                print(\"Downloaded file path:\", audio_file_path)\n",
    "                print(\"Exists?\", os.path.isfile(audio_file_path))\n",
    "\n",
    "                os.environ[\"PATH\"] += os.pathsep + r\"C:\\Users\\ACER\\Downloads\\ffmpeg-master-latest-win64-gpl\\bin\"\n",
    "                print(\"PATH:\", os.environ[\"PATH\"])\n",
    "                \n",
    "                # Load Openai Whisper model\n",
    "                \"\"\"remember to install cuda version that matches your gpu: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\"\"\"\n",
    "                whisper_model = whisper.load_model(\"base\", device=\"cuda\")           \n",
    "                print(\"Model device:\", whisper_model.device)\n",
    "                \n",
    "                # Transcribe\n",
    "                cur_transcription = whisper_model.transcribe(audio_file_path, fp16=True)[\"text\"].strip()\n",
    "\n",
    "                export_to_github(title, cur_transcription)\n",
    "\n",
    "                return cur_transcription,title\n",
    "    else:\n",
    "        return check_trans.lower(),title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def text_cleaner(text):\n",
    "    \"\"\"Remove redundant characters that are not alphanumeric\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "    \"\"\"\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(pattern, ' ', text).strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords\n",
    "\n",
    "    Args:\n",
    "        text (str): input text\n",
    "\n",
    "    Returns:\n",
    "        text (str): cleaned text without stopwords\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Preprocessing & Storage Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_document(transcription):\n",
    "    text = transcription\n",
    "    text_documents = [Document(page_content=text)]\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "    documents = text_splitter.split_documents(text_documents)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Embedding Model, Pine Cone DB & Store Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "def store_vector_db(title,documents):\n",
    "    title = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title}-index\"\n",
    "    if index_name not in str(pc.list_indexes()):\n",
    "        pc.create_index(index_name,dimension = 1536, metric = \"cosine\", \n",
    "                        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "                        deletion_protection=\"disabled\")\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore.from_documents(documents=documents, embedding=embeddings, index_name=index_name\n",
    "    )\n",
    "        return pinecone\n",
    "    else:\n",
    "        index = pc.Index(host = pc.describe_index(index_name).host)\n",
    "        pinecone = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "        return pinecone\n",
    "\n",
    "def reset_index(title):\n",
    "    index_name = f\"{title}-index\"\n",
    "    index = pc.Index(host= pc.describe_index(index_name).host)\n",
    "    index.delete_index(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ExtractVideoTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        transcription, title = extract_transcription(X)\n",
    "        return {\"transcription\": transcription, \"title\": title}\n",
    "\n",
    "class CleanTranscription(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        trans = remove_stopwords(text_cleaner(X[\"transcription\"]))\n",
    "        return {\"transcription\": trans, \"title\": X[\"title\"]}\n",
    "\n",
    "class SplitDocuments(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        documents = split_document(X[\"transcription\"])\n",
    "        return {\"documents\": documents, \"title\": X[\"title\"]}\n",
    "\n",
    "class StoreVectorDB(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        title = X[\"title\"]\n",
    "        documents = X[\"documents\"]\n",
    "        store_vector_db(title,documents)\n",
    "        return {\"documents\": documents, \"title\": title}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Extraction & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for file data_trans/jensen_huang_--_nvidias_ceo_on_the_nex.txt...\n",
      "200\n",
      "Found file. Downloading...\n"
     ]
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"extract\", ExtractVideoTranscription()),\n",
    "    (\"clean\", CleanTranscription()),\n",
    "    (\"split\", SplitDocuments()),\n",
    "    (\"store\", StoreVectorDB()),\n",
    "])\n",
    "\n",
    "preprocessed_dict = preprocessing_pipeline.fit_transform(str(input(\"Enter a youtube url: \")))\n",
    "documents, title = preprocessed_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 1: Context-Based Querying Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "# define an query rewriting agent for current query + most recent chat history\n",
    "def retrieve_history(k=3):\n",
    "    k = k*2\n",
    "    history = memory.load_memory_variables({}).get(\"history\")[-k:]\n",
    "    pattern = r\"^(content=')(.*?)(' .*?)$\"\n",
    "    a=1\n",
    "    b=0\n",
    "    cleaned_dict={}\n",
    "    for idx,i in enumerate(history):\n",
    "        output = re.sub(pattern=pattern,string=str(i),repl=r\"\\2\")\n",
    "        name = \"Human\" if idx%2==0 else \"AI\"\n",
    "        question_no = a\n",
    "        b+=1\n",
    "        if b >= 2:\n",
    "            b=0\n",
    "            a+=1\n",
    "        if b==1:\n",
    "            cleaned_dict[f'Question {question_no}'] = {}\n",
    "        cleaned_dict[f'Question {question_no}'][name] = output\n",
    "    return cleaned_dict\n",
    "\n",
    "def rewrite_query(new_query):\n",
    "    current_hist = retrieve_history()\n",
    "    history = str(current_hist)\n",
    "    rewrite_prompt = [\n",
    "        SystemMessage(content=\"You are a helpful query rewriting assistant. Rewrite the user's query based on their recent history. Return only the rewritten query.\"),\n",
    "        HumanMessage(content=f\"History: {history}\\nNew query: {new_query}\")\n",
    "    ]\n",
    "    outcome = model.invoke(rewrite_prompt).content # may modify using a nicher model\n",
    "    print(f\"Rewritten Query: {outcome}\")\n",
    "    return outcome\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def retrieve_context(input):\n",
    "    try:\n",
    "        # Extract the content from the message object\n",
    "        if isinstance(input, dict) and \"question\" in input:\n",
    "            input = input[\"question\"][-1].content  # Extract human question only\n",
    "        elif isinstance(input, str):\n",
    "            input = input  # Directly use the string if provided\n",
    "        else:\n",
    "            raise ValueError(\"Input is not in a valid format.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing input: {e}\")\n",
    "        return None\n",
    "    \n",
    "    if detect(input) != \"en\":\n",
    "        query = translator.translate(input)\n",
    "        print(f\"Translated query: {query}\")\n",
    "    else:\n",
    "        query = input\n",
    "        print(f\"Original text already in English\")\n",
    "    \n",
    "    context = store_vector_db(title,documents) \\\n",
    "                .as_retriever(search_type = \"similarity_score_threshold\",search_kwargs={'score_threshold': 0.5}) \\\n",
    "                .get_relevant_documents(query)\n",
    "    compiled_docu = \" \".join([doc.page_content for doc in context])\n",
    "    print(\"Retrieved Context:\", compiled_docu, \"\\n-----\\n\")\n",
    "    return compiled_docu\n",
    "\n",
    "def query_from_context_main():\n",
    "    template = \"\"\"\n",
    "    Think step by step before answering the question based on the context below. If you can't find the answer in the context below, say that you don't know.\n",
    "\n",
    "    **Context:** {context}\n",
    "\n",
    "    **Question:** {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    rewriter = RunnableLambda(rewrite_query)\n",
    "\n",
    "    retriever_step = RunnableLambda(retrieve_context)\n",
    "    retriever = RunnableParallel(context = retriever_step,\n",
    "                        question=RunnablePassthrough(), \n",
    "                        #  language = RunnablePassthrough()\n",
    "                        )\n",
    "    if memory.load_memory_variables({}).get(\"history\") == []:\n",
    "        chain = retriever | prompt | model | parser\n",
    "    else:\n",
    "        chain = rewriter | retriever | prompt | model | parser\n",
    "    return chain\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n",
    "\n",
    "def web_search_tool(query):\n",
    "    try:\n",
    "        query = query[\"question\"][1].content # Extract human question only\n",
    "    except Exception as e:\n",
    "        query = query\n",
    "    web_search_tool = TavilySearchResults(k=3)\n",
    "    results = web_search_tool.invoke(query)\n",
    "    extracted_results = \"\\n\".join([remove_stopwords(re.sub(r\"[^a-zA-Z0-9\\s.,!?]\",\"\",res[\"content\"].replace(\"\\n\",\" \").strip())) for res in results])\n",
    "    return extracted_results\n",
    "\n",
    "def alternative_web_search_context(prev_result):\n",
    "     if \"i don't know\" in prev_result.lower():\n",
    "          return True\n",
    "\n",
    "def build_chain_web():\n",
    "    rewriter = RunnableLambda(rewrite_query)\n",
    "\n",
    "    search_step = RunnableLambda(lambda q: web_search_tool(q))  # Search condition\n",
    "    retriever_web = RunnableParallel(context=search_step, question=RunnablePassthrough())\n",
    "    web_prompt = ChatPromptTemplate.from_template(\"Web search-based context:\\n{context}\\n\\n**Question:** {question}\")\n",
    "    if memory.load_memory_variables({}).get(\"history\") == []:\n",
    "        webchain = retriever_web | web_prompt | model | parser\n",
    "    else:\n",
    "        webchain = rewriter | retriever_web | web_prompt | model | parser\n",
    "    \n",
    "    return webchain\n",
    "\n",
    "\"\"\"-----------------------------------------------------------------\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"608pt\" height=\"560pt\"\n",
       " viewBox=\"0.00 0.00 608.47 559.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 555.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-555.5 604.47,-555.5 604.47,4 -4,4\"/>\n",
       "<!-- A -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>A</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"312.68\" cy=\"-533.5\" rx=\"80.01\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.68\" y=\"-528.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Start Conversation</text>\n",
       "</g>\n",
       "<!-- B -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>B</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"312.68\" cy=\"-460.5\" rx=\"64.66\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.68\" y=\"-455.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Check History</text>\n",
       "</g>\n",
       "<!-- A&#45;&gt;B -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>A&#45;&gt;B</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.68,-515.31C312.68,-507.73 312.68,-498.6 312.68,-490.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"316.18,-490.04 312.68,-480.04 309.18,-490.04 316.18,-490.04\"/>\n",
       "</g>\n",
       "<!-- C -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>C</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-283.5\" rx=\"109.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query from Context Main</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;C -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>B&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M249.3,-456.32C202.57,-450.26 141.91,-433.78 110.68,-390 94.42,-367.2 104.13,-334.84 114.93,-311.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.95,-313.76 119.36,-303.26 111.71,-310.59 117.95,-313.76\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.68\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">If History is Blank</text>\n",
       "</g>\n",
       "<!-- D -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>D</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"348.68\" cy=\"-283.5\" rx=\"74.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.68\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Build Chain Web</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;D -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>B&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.15,-451C398.06,-445.17 430.67,-436.33 439.68,-424.5 447.04,-414.84 470.67,-369.87 434.68,-319.5 429.16,-311.77 421.62,-305.74 413.29,-301.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"415.09,-298.03 404.57,-296.79 412.02,-304.32 415.09,-298.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"505.11\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">If History is Blank</text>\n",
       "</g>\n",
       "<!-- K -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>K</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"319.68\" cy=\"-372\" rx=\"97.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.68\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query Rewriting Agent</text>\n",
       "</g>\n",
       "<!-- B&#45;&gt;K -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>B&#45;&gt;K</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.37,-442.3C312.35,-432.27 312.6,-419.4 313.68,-408 313.88,-405.93 314.13,-403.79 314.41,-401.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"317.85,-402.29 315.94,-391.87 310.94,-401.21 317.85,-402.29\"/>\n",
       "<text text-anchor=\"middle\" x=\"376.68\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">If History is Not Blank</text>\n",
       "</g>\n",
       "<!-- E -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>E</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-195\" rx=\"73.87\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Retrieve Context</text>\n",
       "</g>\n",
       "<!-- C&#45;&gt;E -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>C&#45;&gt;E</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-265.41C130.68,-253.76 130.68,-238.05 130.68,-224.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-224.86 130.68,-214.86 127.18,-224.86 134.18,-224.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.81\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Retrieve Context</text>\n",
       "</g>\n",
       "<!-- F -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>F</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"348.68\" cy=\"-195\" rx=\"74.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.68\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Web Search Tool</text>\n",
       "</g>\n",
       "<!-- D&#45;&gt;F -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>D&#45;&gt;F</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M348.68,-265.41C348.68,-253.76 348.68,-238.05 348.68,-224.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"352.18,-224.86 348.68,-214.86 345.18,-224.86 352.18,-224.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.18\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Web Search Tool</text>\n",
       "</g>\n",
       "<!-- H -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>H</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-106.5\" rx=\"77.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Main Result</text>\n",
       "</g>\n",
       "<!-- E&#45;&gt;H -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>E&#45;&gt;H</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-176.91C130.68,-165.26 130.68,-149.55 130.68,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-136.36 130.68,-126.36 127.18,-136.36 134.18,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"179.43\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Main Result</text>\n",
       "</g>\n",
       "<!-- I -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>I</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"348.68\" cy=\"-106.5\" rx=\"73.87\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.68\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Web Result</text>\n",
       "</g>\n",
       "<!-- F&#45;&gt;I -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>F&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M348.68,-176.91C348.68,-165.26 348.68,-149.55 348.68,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"352.18,-136.36 348.68,-126.36 345.18,-136.36 352.18,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"394.81\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Print Web Result</text>\n",
       "</g>\n",
       "<!-- G -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>G</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.68\" cy=\"-18\" rx=\"130.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.68\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Alternative Web Search Context</text>\n",
       "</g>\n",
       "<!-- G&#45;&gt;I -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>G&#45;&gt;I</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.92,-29.3C257.22,-34.52 281.13,-42.33 301.68,-54 312.85,-60.34 322.83,-70.27 330.7,-79.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.71,-81.59 336.62,-87.32 333.23,-77.29 327.71,-81.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.07\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Switch to Web Search</text>\n",
       "</g>\n",
       "<!-- H&#45;&gt;G -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>H&#45;&gt;G</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.68,-88.41C130.68,-76.76 130.68,-61.05 130.68,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.18,-47.86 130.68,-37.86 127.18,-47.86 134.18,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.93\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Check Alternative Web Search</text>\n",
       "</g>\n",
       "<!-- J -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>J</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"487.68\" cy=\"-533.5\" rx=\"77.45\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.68\" y=\"-528.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">End Conversation</text>\n",
       "</g>\n",
       "<!-- H&#45;&gt;J -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>H&#45;&gt;J</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.9,-116.17C218.79,-118.95 243.27,-121.96 265.68,-124.5 305.41,-129 411.38,-120.37 444.68,-142.5 458.03,-151.37 585.75,-280.6 559.68,-390 549.32,-433.47 523.46,-478.69 505.73,-506.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"503.01,-504 500.44,-514.28 508.86,-507.84 503.01,-504\"/>\n",
       "</g>\n",
       "<!-- I&#45;&gt;J -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>I&#45;&gt;J</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M416.22,-114.14C439.16,-119.1 463.75,-127.68 482.68,-142.5 566.94,-208.45 571.31,-250.3 597.68,-354 613.38,-415.73 556.23,-476.46 518.48,-508.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"516.44,-505.87 510.99,-514.95 520.92,-511.25 516.44,-505.87\"/>\n",
       "</g>\n",
       "<!-- K&#45;&gt;C -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>K&#45;&gt;C</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M247.13,-359.66C225.81,-354.42 203.03,-346.86 183.68,-336 171.86,-329.37 160.77,-319.43 151.82,-310.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.57,-307.89 145.26,-302.84 149.39,-312.59 154.57,-307.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.68\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Query from Context Main</text>\n",
       "</g>\n",
       "<!-- K&#45;&gt;D -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>K&#45;&gt;D</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M325.41,-353.91C329.36,-342.14 334.69,-326.23 339.26,-312.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"342.52,-313.88 342.38,-303.29 335.89,-311.65 342.52,-313.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.65\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Build Chain Web</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x242044c8560>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_flow():\n",
    "    dot = Digraph(comment='Code Flow')\n",
    "\n",
    "    # Define nodes\n",
    "    dot.node('A', 'Start Conversation')\n",
    "    dot.node('B', 'Check History')\n",
    "    dot.node('C', 'Query from Context Main')\n",
    "    dot.node('D', 'Build Chain Web')\n",
    "    dot.node('E', 'Retrieve Context')\n",
    "    dot.node('F', 'Web Search Tool')\n",
    "    dot.node('G', 'Alternative Web Search Context')\n",
    "    dot.node('H', 'Print Main Result')\n",
    "    dot.node('I', 'Print Web Result')\n",
    "    dot.node('J', 'End Conversation')\n",
    "    dot.node('K', 'Query Rewriting Agent')\n",
    "\n",
    "    # Define edges\n",
    "    dot.edges(['AB'])\n",
    "    dot.edge('B', 'C', label='If History is Blank')\n",
    "    dot.edge('B', 'D', label='If History is Blank')\n",
    "    dot.edge('B', 'K', label='If History is Not Blank')\n",
    "    dot.edge('K', 'C', label='Query from Context Main')\n",
    "    dot.edge('K', 'D', label='Build Chain Web')\n",
    "    dot.edge('C', 'E', label='Retrieve Context')\n",
    "    dot.edge('D', 'F', label='Web Search Tool')\n",
    "    dot.edge('E', 'H', label='Print Main Result')\n",
    "    dot.edge('F', 'I', label='Print Web Result')\n",
    "    dot.edge('H', 'G', label='Check Alternative Web Search')\n",
    "    dot.edge('G', 'I', label='Switch to Web Search', constraint='false')\n",
    "    dot.edge('H', 'J', constraint='false')\n",
    "    dot.edge('I', 'J', constraint='false')\n",
    "\n",
    "    return dot\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "dot = visualize_flow()\n",
    "display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_conversation():    \n",
    "    \n",
    "    system_message = SystemMessage(content=\"You are a truthful expert in extracting insights from provided context for QnA.\")\n",
    "    question_no = 0\n",
    "\n",
    "    memory.clear()\n",
    "    print(f\"Check history: {memory.load_memory_variables({}).get(\"history\")}\")\n",
    "    \n",
    "    while True:\n",
    "        query = str(input(\"Ask me a question (type 'exit' to quit): \")).lower()\n",
    "\n",
    "        human_message = HumanMessage(content=query)\n",
    "        messages = [system_message,human_message]\n",
    "\n",
    "        if query == 'exit':\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "        \n",
    "        question_no += 1\n",
    "        print(f\"\\nQuestion {question_no}:\")\n",
    "        \n",
    "        chain_main = query_from_context_main()\n",
    "        main_result = []\n",
    "        for s in chain_main.stream({\"question\":messages}):\n",
    "            main_result.append(s)\n",
    "            print(s, end =\"\",flush=True)\n",
    "        \n",
    "        if alternative_web_search_context(\"\".join(main_result)):\n",
    "            feedback = str(input(\"Would you like to switch to web search tool? (yes/no): \"))\n",
    "            if feedback.lower() == 'yes':\n",
    "                print(f\"\\nSwitching to web search tool...\")\n",
    "                chain_web = build_chain_web()\n",
    "                for s in chain_web.stream({\"question\":messages}):\n",
    "                    main_result.append(s)\n",
    "                    print(s, end =\"\",flush=True)\n",
    "            else:\n",
    "                print(\"\\nPlease ask a different question.\")\n",
    "                pass\n",
    "        memory.chat_memory.add_user_message(query) # add user query to memory\n",
    "        memory.chat_memory.add_ai_message(\"\".join(main_result)) # add ai result to memory\n",
    "        print(\"\\n\",\"---\"*20,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check history: []\n",
      "\n",
      "Question 1:\n",
      "Original text already in English\n",
      "Retrieved Context: start routing ill show im going build router ill show really simple trick local lms like simply im going set prompt says youre expert routing vector store contains documents related agents prompt engineering adial tax use vector store questions topics everything else especially current events use web search heres instruct return json object single key data source either web search vector store depending question use llm json mode go right ive set format json going enforce output lm json whats nice ive built simple little router using kind llm json mode need im going pass question one thing want mention chat model pass set chat messages import lang chain core messages human message system message system message router instructions human message whatever question types agent memory passed hey lance lang chain meta released llama 32 today really exciting ive looking forward whats really neat use increasingly small models pretty interesting things locally devices today im going show go scratch build fairly complex rag agent using 3 billion parameter model run locally laptop diagram shows entire flow agent ill zoom going able take questions route using model either index web search grade documents retrieval based relevance question produce answer grade answer hallucinations grade relevance question finally return answer user logic locally llama 32 3 billion parameter model ill show shortly first theres kind two two variants models theres compact theres vision models theres 1 billion 3 billion parameter compact model going working 3 billion theres also vision models interesting splitting chunks size th000 tokens im going add vector store free use vector store sklearn load document splits load embedding heres im going using nomic local embeddings uh free use im going create retriever lets get started retriever line chain abstraction gives common methods use invoke simply agent memory get documents related input go weve retrieved documents relevant question statement agent memory course whats happening taking statement embedding using model similarity search embedded documents find similar matches based upon semantics question relative documents thats get documents back retriever retriever see falls flow kind one core components rag system need document reval mechanism weve built lets build logic around first lets start routing ill show im going build router ill 3 billion theres also vision models interesting reasons may talk future video compact models meant smaller uh device use cases um whats kind cool show statistics comparing prior 8 billion current 323 billion pretty pretty close 3 versus 8 see 3 billion parameter model strong one evals pretty promising telling us smaller models getting indeed better opens access folks exciting want talk little bit rag agent going build lets get code going incorporate ideas three papers one routing thats ability take question route either vector store web search based model content question fallback idea basically retrieve documents grade documents relevant filter big problem retrieval erroneous retrievals fallback self correction fix catch hallucinations basically reject answers dont uh address question \n",
      "-----\n",
      "\n",
      "I don't know.\n",
      "Please ask a different question.\n",
      "\n",
      " ------------------------------------------------------------ \n",
      "\n",
      "\n",
      "Question 2:\n",
      "Rewritten Query: what activities are taking place in the video?\n",
      "Original text already in English\n",
      "Retrieved Context: weve used llm produce uh answers using rag web search tool document grader tool retriever interesting components heres question actually orchestrate flow tie together thats want introduce idea lang graph lang graph agent orchestration tool built use quite extensively theres videos want show use orchestrate whole workflow really easily running locally laptop first part l graph actually defining state thats going live across entire agent flow state basically going set things going like schema nodes access rag going things intuitive rag process going like input question retrieve documents answer things input output steps individually im going save common state thats going persist throughout agents lifetime lang graph whats cool lang graph go ahead define state class flexible use type dick goes web search search node runs tav returns web search results pretty nice go generate runs chatow llama case generates answer question question related agent memory two categories agent memory short term longterm forth based upon web search retrieval answers question conditional edge grade uh hallucinations particular case deems uh answer grounded thats cool look grading finally graded um see yes uh answer helpfulness deems actually helpful actually addresses question thats entire flow agent whole bunch different things running locally laptop using 3 billion parameter model thats pretty neat go back kind show notebook ill make sure accessible play free use im using local free embeddings im using locally running three billion parameter model im orchestrating using l graph orchestrate hey lance lang chain meta released llama 32 today really exciting ive looking forward whats really neat use increasingly small models pretty interesting things locally devices today im going show go scratch build fairly complex rag agent using 3 billion parameter model run locally laptop diagram shows entire flow agent ill zoom going able take questions route using model either index web search grade documents retrieval based relevance question produce answer grade answer hallucinations grade relevance question finally return answer user logic locally llama 32 3 billion parameter model ill show shortly first theres kind two two variants models theres compact theres vision models theres 1 billion 3 billion parameter compact model going working 3 billion theres also vision models interesting splitting chunks size th000 tokens im going add vector store free use vector store sklearn load document splits load embedding heres im going using nomic local embeddings uh free use im going create retriever lets get started retriever line chain abstraction gives common methods use invoke simply agent memory get documents related input go weve retrieved documents relevant question statement agent memory course whats happening taking statement embedding using model similarity search embedded documents find similar matches based upon semantics question relative documents thats get documents back retriever retriever see falls flow kind one core components rag system need document reval mechanism weve built lets build logic around first lets start routing ill show im going build router ill \n",
      "-----\n",
      "\n",
      "The video appears to showcase the orchestration of a complex retrieval-augmented generation (RAG) agent workflow using a 3 billion parameter language model. Key activities include:\n",
      "\n",
      "1. **Defining State in Lang Graph**: The speaker discusses defining a state that is shared across the entire agent flow, which includes setting schemas and nodes for accessing RAG processes.\n",
      "\n",
      "2. **Running Local Models**: It highlights the execution of the model locally on a laptop, indicating the use of free embeddings and the orchestration of model components.\n",
      "\n",
      "3. **Web Search and Document Retrieval**: The agent utilizes web search to retrieve documents relevant to input questions, with a focus on processing these documents intuitively.\n",
      "\n",
      "4. **Answer Generation and Grading**: The process includes generating answers to questions based on the retrieved documents and grading these answers for helpfulness and relevance, particularly in addressing hallucinations in responses.\n",
      "\n",
      "5. **Agent Memory Management**: Thereâ€™s a discussion about managing short-term and long-term memory within the agent to enhance its ability to retrieve and respond to questions effectively.\n",
      "\n",
      "6. **Building a Router**: The speaker plans to build a routing logic to facilitate the flow of information and document retrieval based on user input.\n",
      "\n",
      "7. **Demonstrating the Workflow**: The video aims to demonstrate the entire workflow in action, showing how different components are integrated and how users can interact with the system.\n",
      "\n",
      "Overall, the video illustrates the construction and demonstration of a RAG agent that can efficiently retrieve information, generate answers, and assess the quality of those answers in a user-friendly manner.\n",
      " ------------------------------------------------------------ \n",
      "\n",
      "\n",
      "Question 3:\n",
      "Rewritten Query: how can we design and implement a routing logic for information flow in a retrieval-augmented generation agent?\n",
      "Original text already in English\n",
      "Retrieved Context: whatever question types agent memory passed list thats go ahead run go ahead run see looks question reasons oh data source vector store get little json back says data source vector store build simple router using json mode local lm use time extremely convenient way really simple kind binary routing using llm reason input return structured object like json example two outputs want either vector store web search built red router piece next im going build blue greater piece go also really simple lets give instructions grading main idea want look retriev documents determine theyre relevant question ask sometimes semantic similarity search get kind erroneous retrievals documents particularly relevant question uh happen returned based upon idiosyncrasies chunking embedding model happen start routing ill show im going build router ill show really simple trick local lms like simply im going set prompt says youre expert routing vector store contains documents related agents prompt engineering adial tax use vector store questions topics everything else especially current events use web search heres instruct return json object single key data source either web search vector store depending question use llm json mode go right ive set format json going enforce output lm json whats nice ive built simple little router using kind llm json mode need im going pass question one thing want mention chat model pass set chat messages import lang chain core messages human message system message system message router instructions human message whatever question types agent memory passed web search vector store based upon question thats router built first going retrieval well grade documents documents relevant going go ahead web search supplement web search otherwise well go generate web search well go generate weve done generate two checks one generation supported documents theres hallucinations case retry thats representing actually useful doesnt actually answer question occurs kick back retry web search thats kind current logic graph modify accordingly thats whats going go two fallbacks finally answer either useful means supported hallucinations useful answers question max retries thats another way end thats overall connectivity graph weve put together l graph zoom way back weve used ama weve used ama load llama 3b uh fp16 llm json mode ive tested components weve used llm produce uh answers using rag web search tool document grader tool retriever interesting components heres question actually orchestrate flow tie together thats want introduce idea lang graph lang graph agent orchestration tool built use quite extensively theres videos want show use orchestrate whole workflow really easily running locally laptop first part l graph actually defining state thats going live across entire agent flow state basically going set things going like schema nodes access rag going things intuitive rag process going like input question retrieve documents answer things input output steps individually im going save common state thats going persist throughout agents lifetime lang graph whats cool lang graph go ahead define state class flexible use type dick \n",
      "-----\n",
      "\n",
      "To design and implement a routing logic for information flow in a retrieval-augmented generation (RAG) agent, you can follow these steps based on the provided context:\n",
      "\n",
      "1. **Define the Routing Logic**: Start by determining how to route questions to different data sources based on the content of the questions. In the context, there are two main data sources mentioned: a vector store and web search. You need to create a routing mechanism that decides which source to query based on the question type.\n",
      "\n",
      "2. **Set Up Input Processing**: Use a large language model (LLM) to process the input question. The model should be able to understand the context and based on the semantics of the question, decide whether to query the vector store or perform a web search.\n",
      "\n",
      "3. **Implement JSON Mode**: Format the output in JSON to facilitate structured communication. For instance, the output can include a key that indicates the chosen data source (either \"web search\" or \"vector store\") along with the relevant data.\n",
      "\n",
      "4. **Create a Simple Router**: Build a simple router that takes the input question and routes it to the appropriate retrieval method. This can be done by setting instructions for the LLM to classify the question and choose the correct source.\n",
      "\n",
      "5. **Handle Document Retrieval**: For both sources, implement a mechanism to retrieve documents. In case of the vector store, retrieve relevant documents based on semantic similarity to the question. For web searches, perform the search and retrieve relevant results.\n",
      "\n",
      "6. **Error Handling and Hallucination Management**: Incorporate logic to handle erroneous retrievals. If the documents returned do not adequately answer the question (i.e., hallucinations), implement a retry mechanism. This could involve re-querying the web search or refining the retrieval from the vector store.\n",
      "\n",
      "7. **Grade Document Relevance**: After retrieving documents, implement a grading mechanism to evaluate their relevance to the question. This can help in filtering out irrelevant information and ensuring that only useful documents are passed on for answer generation.\n",
      "\n",
      "8. **Connect Components with Lang Graph**: Utilize a tool like Lang Graph for orchestration. This tool can help manage the flow of information between the various components of the RAG agent. Define state classes that represent different stages of processing and ensure that information persists throughout the agent's lifecycle.\n",
      "\n",
      "9. **Testing and Iteration**: Test the routing logic with various types of questions to ensure robustness. Make adjustments as necessary based on the performance of the routing and retrieval processes.\n",
      "\n",
      "By following these steps, you can effectively design and implement a routing logic for information flow in a retrieval-augmented generation agent.\n",
      " ------------------------------------------------------------ \n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "start_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: (Advanced) Summarization Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/28/2024 01:53:08 INFO Loaded model pszemraj/led-large-book-summary to cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from textsum.summarize import Summarizer\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "model_name = \"pszemraj/led-large-book-summary\"\n",
    "summarizer = Summarizer(\n",
    "    model_name_or_path=model_name\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "translator = GoogleTranslator(source=\"vi\", target=\"en\")\n",
    "\n",
    "def fetch_list_pinecone(title) -> pd.DataFrame:\n",
    "    # Define index\n",
    "    title_refined = title.replace(\"_\",\"-\")\n",
    "    index_name = f\"{title_refined}-index\"\n",
    "\n",
    "    index = pc.Index(name = index_name, host = pc.describe_index(index_name).host)\n",
    "\n",
    "    # Define vector_id\n",
    "    id_list = []\n",
    "    for id in index.list():\n",
    "        for i in id:\n",
    "            id_list.append(i)\n",
    "\n",
    "    # Fetch vector list including metadata\n",
    "    fetch_list = index.fetch(ids=id_list)\n",
    "\n",
    "    # Return df of id, text, vector values\n",
    "    list_vec = []\n",
    "    for key, content in fetch_list[\"vectors\"].items():\n",
    "        id = key\n",
    "        text = content[\"metadata\"][\"text\"]\n",
    "        values = content[\"values\"]\n",
    "        list_vec.append([id,text,values])\n",
    "    \n",
    "    df_vec_extracted = pd.DataFrame(list_vec, columns=[\"id\", \"text\", \"values\"])\n",
    "\n",
    "    return df_vec_extracted\n",
    "\n",
    "def preprocess_run_kmeans(df_vec_extracted, n = 8) -> pd.DataFrame:\n",
    "    # Split vector values to a separate df to run kmeans\n",
    "    df_vec_text = df_vec_extracted.iloc[:,:2]\n",
    "\n",
    "    df_vec_val = df_vec_extracted.loc[:,[\"id\",\"values\"]]\n",
    "    df_vec_val = pd.concat([df_vec_val[[\"id\"]], pd.DataFrame(df_vec_val[\"values\"].tolist())],axis=1)    \n",
    "\n",
    "    n_clusters = n\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df_vec_val[\"cluster\"] = kmeans.fit_predict(df_vec_val.iloc[:, 1:])\n",
    "    df_vec_text_clustered = pd.merge(df_vec_text,df_vec_val[\"cluster\"],right_index=True,left_index=True)\n",
    "    \n",
    "    # Return final clustered results in df form\n",
    "    clustered_texts = df_vec_text_clustered.groupby(\"cluster\")[\"text\"].apply(\" \".join).reset_index()\n",
    "    return clustered_texts\n",
    "\n",
    "def summarize_text(input):\n",
    "    out_str = summarizer.summarize_string(input)\n",
    "    return out_str\n",
    "\n",
    "def pre_summarize_chunk(title):\n",
    "    df_vec_extracted = fetch_list_pinecone(title)\n",
    "    clustered_texts = preprocess_run_kmeans(df_vec_extracted)\n",
    "    clustered_texts[\"summarized_text\"] = clustered_texts[\"text\"].apply(lambda x: summarize_text(x))\n",
    "    input_sum=\"; \".join(clustered_texts[\"summarized_text\"].values)\n",
    "    return input_sum\n",
    "\n",
    "\"\"\"----------------------------------------------------\"\"\"\n",
    "# summary to graph illustration\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files\\Graphviz\\bin'\n",
    "from src._generate_summary_graph import *\n",
    "\n",
    "def generate_graph(text):\n",
    "    # Generate the Graphviz code\n",
    "    print(\"Generating mind map...\")\n",
    "    graph_code = generate_graph_code(model,text)\n",
    "\n",
    "    # Display the Graphviz code\n",
    "    print(\"Generated Graphviz Code:\")\n",
    "    print(graph_code)\n",
    "\n",
    "    # Render and display the graph\n",
    "    print(\"Displaying mind map...\")\n",
    "    graph = display_graph(graph_code)\n",
    "    if graph:\n",
    "        display(graph)\n",
    "\n",
    "\"\"\"-----------------------------------------------------\"\"\"\n",
    "\n",
    "def summarize_main(title=title):\n",
    "    summarize_temp = \"\"\"\n",
    "    **Summarize the main points** and organize the information into a coherent summary based on the following context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Ensure the summary is concise, clear, and covers all key details.\n",
    "    \"\"\"\n",
    "\n",
    "    summarize_prompt = ChatPromptTemplate.from_template(summarize_temp)\n",
    "\n",
    "    input_sum = pre_summarize_chunk(title)\n",
    "\n",
    "    graph_maker = RunnableLambda(generate_graph)\n",
    "\n",
    "    # Summarization chain of actions\n",
    "    \n",
    "    sum_chain = summarize_prompt | model | parser\n",
    "    sum_chunk = []\n",
    "\n",
    "    for s in sum_chain.stream(input_sum):\n",
    "        sum_chunk.append(s)\n",
    "        print(s, end=\"\", flush=True)\n",
    "    \n",
    "    graph_demand = str(input(\"Would you like to generate a mindmap of this summary? (yes/no): \")).lower()\n",
    "    if graph_demand == \"yes\":\n",
    "        generate_graph(\"\".join(sum_chunk))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d46f82b808041c088df7c9cf5062228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1faa8a80914bd2adada2c7bbe83a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba4aecaa16d400d8d25504c42db0c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5855fea4863d48aaacdc82b29c6805d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfffaf714b84dd0ba24b79039360f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bafc624fbd84e4d8c5774f8afd8e8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe0aca1df814764b001712a07311b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951c9c2d94cc4e1293f34ae61d1841b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Summaries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/28/2024 01:37:41 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text discusses the transformative impact of artificial intelligence (AI) and accelerated computing, particularly through the contributions of Nvidia and its CEO Jensen Huang. Key points include:\n",
      "\n",
      "1. **Democratization of Scientific Computing**: AI has made advanced scientific computing accessible to a broader audience, enabling individuals to learn and apply complex techniques that were previously challenging.\n",
      "\n",
      "2. **Nvidia's Innovations**: Nvidia has been a pioneer in the semiconductor industry and accelerated computing, developing technologies that have revolutionized fields like machine vision and deep learning. Their achievements include the creation of a homemade supercomputer, the \"Bespokea supercomputer.\"\n",
      "\n",
      "3. **Experience and Knowledge**: Jensen Huang acknowledges the varied experience levels within his team, highlighting that even younger team members are making significant contributions despite previous gaps in their knowledge.\n",
      "\n",
      "4. **Future Applications**: The text anticipates future advancements in robotics and AI applications, particularly in areas like autonomous driving and medicine. The \"Omniverse Lukas\" theme emphasizes unity and multimedia connections in future technologies.\n",
      "\n",
      "5. **Recognition and Motivation**: An annual achievement bonus is discussed as a form of recognition for employee contributions, fostering satisfaction and motivation across the company.\n",
      "\n",
      "6. **Continuous Innovation**: Nvidia is committed to pushing the boundaries of technology and encouraging its employees to innovate continually, with a focus on practical applications of machine learning and deep learning.\n",
      "\n",
      "7. **Research Interests**: The narrator, a graduate student in machine learning, expresses a desire to explore Jensen's work and the field's significance, aiming to contribute to the understanding of machine learning's importance and potential.\n",
      "\n",
      "Overall, the text highlights Nvidia's role in advancing AI and computing, the ongoing importance of innovation, and the exciting future possibilities in technology.Generating mind map...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/28/2024 01:44:05 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Graphviz Code:\n",
      "digraph G {\n",
      "    rankdir=TB;\n",
      "    node [shape=box];\n",
      "\n",
      "    AIImpact [label=\"Transformative Impact of AI and Accelerated Computing\"];\n",
      "    \n",
      "    Democratization [label=\"Democratization of Scientific Computing\"];\n",
      "    Innovations [label=\"Nvidia's Innovations\"];\n",
      "    Experience [label=\"Experience and Knowledge\"];\n",
      "    FutureApplications [label=\"Future Applications\"];\n",
      "    Recognition [label=\"Recognition and Motivation\"];\n",
      "    ContinuousInnovation [label=\"Continuous Innovation\"];\n",
      "    ResearchInterests [label=\"Research Interests\"];\n",
      "    \n",
      "    Nvidia [label=\"Nvidia\"];\n",
      "    JensenHuang [label=\"Jensen Huang\"];\n",
      "    \n",
      "    AIImpact -> Democratization;\n",
      "    AIImpact -> Innovations;\n",
      "    AIImpact -> Experience;\n",
      "    AIImpact -> FutureApplications;\n",
      "    AIImpact -> Recognition;\n",
      "    AIImpact -> ContinuousInnovation;\n",
      "    AIImpact -> ResearchInterests;\n",
      "    \n",
      "    Innovations -> Nvidia;\n",
      "    Innovations -> \"Bespokea Supercomputer\";\n",
      "    \n",
      "    Experience -> JensenHuang;\n",
      "    Experience -> \"Younger Team Members\";\n",
      "    \n",
      "    FutureApplications -> \"Autonomous Driving\";\n",
      "    FutureApplications -> \"Medicine\";\n",
      "    FutureApplications -> \"Omniverse Lukas\";\n",
      "    \n",
      "    Recognition -> \"Annual Achievement Bonus\";\n",
      "    \n",
      "    ContinuousInnovation -> \"Practical Applications of ML and DL\";\n",
      "    \n",
      "    ResearchInterests -> \"Graduate Student in Machine Learning\";\n",
      "    ResearchInterests -> \"Contribute to Understanding of ML\";\n",
      "}\n",
      "Displaying mind map...\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1900pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 1899.75 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 1895.75,-184 1895.75,4 -4,4\"/>\n",
       "<!-- AIImpact -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>AIImpact</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"990.38,-180 660.12,-180 660.12,-144 990.38,-144 990.38,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"825.25\" y=\"-156.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformative Impact of AI and Accelerated Computing</text>\n",
       "</g>\n",
       "<!-- Democratization -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Democratization</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"242.5,-108 0,-108 0,-72 242.5,-72 242.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"121.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Democratization of Scientific Computing</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;Democratization -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;Democratization</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M659.92,-147.41C548.06,-137.81 396.67,-124.05 253.82,-108.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.51,-104.82 244.18,-107.19 253.73,-111.78 254.51,-104.82\"/>\n",
       "</g>\n",
       "<!-- Innovations -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Innovations</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"388.12,-108 260.38,-108 260.38,-72 388.12,-72 388.12,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Nvidia&#39;s Innovations</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;Innovations -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;Innovations</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M700.12,-143.52C605.78,-130.34 479.48,-112.69 399.99,-101.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"400.49,-98.12 390.11,-100.2 399.52,-105.05 400.49,-98.12\"/>\n",
       "</g>\n",
       "<!-- Experience -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Experience</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"630.25,-108 464.25,-108 464.25,-72 630.25,-72 630.25,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"547.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Experience and Knowledge</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;Experience -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;Experience</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M755.82,-143.52C716.78,-133.69 667.87,-121.37 627.24,-111.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"628.3,-107.8 617.75,-108.75 626.59,-114.59 628.3,-107.8\"/>\n",
       "</g>\n",
       "<!-- FutureApplications -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>FutureApplications</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"886.88,-108 763.62,-108 763.62,-72 886.88,-72 886.88,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"825.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Future Applications</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;FutureApplications -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;FutureApplications</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.25,-143.7C825.25,-136.41 825.25,-127.73 825.25,-119.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"828.75,-119.62 825.25,-109.62 821.75,-119.62 828.75,-119.62\"/>\n",
       "</g>\n",
       "<!-- Recognition -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Recognition</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1126.12,-108 956.38,-108 956.38,-72 1126.12,-72 1126.12,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"1041.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Recognition and Motivation</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;Recognition -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;Recognition</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M879.2,-143.52C908.82,-133.92 945.75,-121.95 976.87,-111.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"977.74,-115.26 986.18,-108.85 975.58,-108.6 977.74,-115.26\"/>\n",
       "</g>\n",
       "<!-- ContinuousInnovation -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>ContinuousInnovation</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1330.5,-108 1190,-108 1190,-72 1330.5,-72 1330.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"1260.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Continuous Innovation</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;ContinuousInnovation -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;ContinuousInnovation</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M933.9,-143.52C1009.7,-131.32 1109.27,-115.3 1178.41,-104.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.85,-107.64 1188.17,-102.6 1177.74,-100.73 1178.85,-107.64\"/>\n",
       "</g>\n",
       "<!-- ResearchInterests -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>ResearchInterests</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1605.75,-108 1490.75,-108 1490.75,-72 1605.75,-72 1605.75,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"1548.25\" y=\"-84.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Research Interests</text>\n",
       "</g>\n",
       "<!-- AIImpact&#45;&gt;ResearchInterests -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>AIImpact&#45;&gt;ResearchInterests</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M990.67,-144.98C1144.86,-130.06 1367.3,-108.52 1478.88,-97.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1479.18,-101.2 1488.8,-96.76 1478.51,-94.24 1479.18,-101.2\"/>\n",
       "</g>\n",
       "<!-- Nvidia -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Nvidia</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"169.25,-36 115.25,-36 115.25,0 169.25,0 169.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"142.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Nvidia</text>\n",
       "</g>\n",
       "<!-- Innovations&#45;&gt;Nvidia -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Innovations&#45;&gt;Nvidia</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M272.45,-71.51C246.86,-62.58 215.39,-51.14 180.18,-36.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.62,-33.45 171.05,-32.84 178.93,-39.92 181.62,-33.45\"/>\n",
       "</g>\n",
       "<!-- Bespokea Supercomputer -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>Bespokea Supercomputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"343,-36 187.5,-36 187.5,0 343,0 343,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"265.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Bespokea Supercomputer</text>\n",
       "</g>\n",
       "<!-- Innovations&#45;&gt;Bespokea Supercomputer -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Innovations&#45;&gt;Bespokea Supercomputer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M309.67,-71.7C302.81,-63.56 294.49,-53.69 286.91,-44.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.76,-42.65 280.64,-37.26 284.41,-47.16 289.76,-42.65\"/>\n",
       "</g>\n",
       "<!-- JensenHuang -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>JensenHuang</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"453.12,-36 361.38,-36 361.38,0 453.12,0 453.12,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"407.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Jensen Huang</text>\n",
       "</g>\n",
       "<!-- Experience&#45;&gt;JensenHuang -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>Experience&#45;&gt;JensenHuang</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M512.28,-71.52C494.02,-62.39 471.47,-51.11 451.96,-41.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"453.63,-38.28 443.12,-36.94 450.5,-44.54 453.63,-38.28\"/>\n",
       "</g>\n",
       "<!-- Younger Team Members -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>Younger Team Members</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"623.5,-36 471,-36 471,0 623.5,0 623.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"547.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Younger Team Members</text>\n",
       "</g>\n",
       "<!-- Experience&#45;&gt;Younger Team Members -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>Experience&#45;&gt;Younger Team Members</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M547.25,-71.7C547.25,-64.41 547.25,-55.73 547.25,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"550.75,-47.62 547.25,-37.62 543.75,-47.62 550.75,-47.62\"/>\n",
       "</g>\n",
       "<!-- Autonomous Driving -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>Autonomous Driving</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"773.38,-36 641.12,-36 641.12,0 773.38,0 773.38,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"707.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Autonomous Driving</text>\n",
       "</g>\n",
       "<!-- FutureApplications&#45;&gt;Autonomous Driving -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>FutureApplications&#45;&gt;Autonomous Driving</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M795.78,-71.52C780.74,-62.6 762.26,-51.63 746.07,-42.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"748.03,-39.12 737.65,-37.03 744.46,-45.15 748.03,-39.12\"/>\n",
       "</g>\n",
       "<!-- Medicine -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>Medicine</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"859.12,-36 791.38,-36 791.38,0 859.12,0 859.12,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"825.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Medicine</text>\n",
       "</g>\n",
       "<!-- FutureApplications&#45;&gt;Medicine -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>FutureApplications&#45;&gt;Medicine</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.25,-71.7C825.25,-64.41 825.25,-55.73 825.25,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"828.75,-47.62 825.25,-37.62 821.75,-47.62 828.75,-47.62\"/>\n",
       "</g>\n",
       "<!-- Omniverse Lukas -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>Omniverse Lukas</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"989.62,-36 876.88,-36 876.88,0 989.62,0 989.62,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"933.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Omniverse Lukas</text>\n",
       "</g>\n",
       "<!-- FutureApplications&#45;&gt;Omniverse Lukas -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>FutureApplications&#45;&gt;Omniverse Lukas</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M852.22,-71.52C865.86,-62.68 882.59,-51.84 897.3,-42.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"898.86,-45.46 905.35,-37.08 895.05,-39.59 898.86,-45.46\"/>\n",
       "</g>\n",
       "<!-- Annual Achievement Bonus -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>Annual Achievement Bonus</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1177.12,-36 1007.38,-36 1007.38,0 1177.12,0 1177.12,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1092.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Annual Achievement Bonus</text>\n",
       "</g>\n",
       "<!-- Recognition&#45;&gt;Annual Achievement Bonus -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>Recognition&#45;&gt;Annual Achievement Bonus</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1053.86,-71.7C1059.66,-63.73 1066.68,-54.1 1073.11,-45.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1075.84,-47.47 1078.9,-37.33 1070.18,-43.35 1075.84,-47.47\"/>\n",
       "</g>\n",
       "<!-- Practical Applications of ML and DL -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>Practical Applications of ML and DL</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1415.25,-36 1195.25,-36 1195.25,0 1415.25,0 1415.25,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1305.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Practical Applications of ML and DL</text>\n",
       "</g>\n",
       "<!-- ContinuousInnovation&#45;&gt;Practical Applications of ML and DL -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>ContinuousInnovation&#45;&gt;Practical Applications of ML and DL</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1271.37,-71.7C1276.44,-63.81 1282.55,-54.3 1288.18,-45.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1290.97,-47.68 1293.44,-37.38 1285.08,-43.9 1290.97,-47.68\"/>\n",
       "</g>\n",
       "<!-- Graduate Student in Machine Learning -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>Graduate Student in Machine Learning</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1662.75,-36 1433.75,-36 1433.75,0 1662.75,0 1662.75,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1548.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Graduate Student in Machine Learning</text>\n",
       "</g>\n",
       "<!-- ResearchInterests&#45;&gt;Graduate Student in Machine Learning -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>ResearchInterests&#45;&gt;Graduate Student in Machine Learning</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1548.25,-71.7C1548.25,-64.41 1548.25,-55.73 1548.25,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1551.75,-47.62 1548.25,-37.62 1544.75,-47.62 1551.75,-47.62\"/>\n",
       "</g>\n",
       "<!-- Contribute to Understanding of ML -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>Contribute to Understanding of ML</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1891.75,-36 1680.75,-36 1680.75,0 1891.75,0 1891.75,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"1786.25\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Contribute to Understanding of ML</text>\n",
       "</g>\n",
       "<!-- ResearchInterests&#45;&gt;Contribute to Understanding of ML -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>ResearchInterests&#45;&gt;Contribute to Understanding of ML</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1606.17,-71.97C1639.34,-62.21 1681.19,-49.9 1716.2,-39.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1716.77,-43.08 1725.38,-36.9 1714.8,-36.37 1716.77,-43.08\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x280c2458a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
